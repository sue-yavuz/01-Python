{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data from CSV in Python\n",
    "The Pandas Library is a useful tool that enables us to read various datasets into a Pandas data frame\n",
    "\n",
    "Let us look at how to read a CSV file in Pandas Library.\n",
    "\n",
    "We use pandas.read_csv() function to read the csv file. In the parentheses, we put the file path along with a quotation mark as an argument, so that pandas will read the file into a data frame from that address. The file path can be either a URL or your local file address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import piplite\n",
    "await piplite.install(['seaborn', 'lxml', 'openpyxl'])\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyodide.http import pyfetch\n",
    "\n",
    "filename = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork/labs/Module%205/data/addresses.csv\"\n",
    "\n",
    "async def download(url, filename):\n",
    "    response = await pyfetch(url)\n",
    "    if response.status == 200:\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(await response.bytes())\n",
    "\n",
    "await download(filename, \"addresses.csv\")\n",
    "\n",
    "df = pd.read_csv(\"addresses.csv\", header=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding column name to the DataFrame\n",
    "We can add columns to an existing DataFrame using its columns attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns =['First Name', 'Last Name', 'Location ', 'City','State','Area Code']\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON file Format\n",
    "JSON (JavaScript Object Notation) is a lightweight data-interchange format. It is easy for humans to read and write.\n",
    "\n",
    "JSON is built on two structures:\n",
    "\n",
    "A collection of name/value pairs. In various languages, this is realized as an object, record, struct, dictionary, hash table, keyed list, or associative array.\n",
    "\n",
    "An ordered list of values. In most languages, this is realized as an array, vector, list, or sequence.\n",
    "\n",
    "JSON is a language-independent data format. It was derived from JavaScript, but many modern programming languages include code to generate and parse JSON-format data. It is a very common data format with a diverse range of applications.\n",
    "\n",
    "The text in JSON is done through quoted string which contains the values in key-value mappings within { }. It is similar to the dictionary in Python.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Python supports JSON through a built-in package called json. To use this feature, we import the json package in Python script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing JSON to a File\n",
    "This is usually called serialization. It is the process of converting an object into a special format which is suitable for transmitting over the network or storing in file or database.\n",
    "\n",
    "To handle the data flow in a file, the JSON library in Python uses the dump() or dumps() function to convert the Python objects into their respective JSON object. This makes it easy to write data to files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "person = {\n",
    "    'first_name' : 'Mark',\n",
    "    'last_name' : 'abc',\n",
    "    'age' : 27,\n",
    "    'address': {\n",
    "        \"streetAddress\": \"21 2nd Street\",\n",
    "        \"city\": \"New York\",\n",
    "        \"state\": \"NY\",\n",
    "        \"postalCode\": \"10021-3100\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "serialization using dump() function\n",
    "json.dump() method can be used for writing to JSON file.\n",
    "\n",
    "Syntax: json.dump(dict, file_pointer)\n",
    "\n",
    "Parameters:\n",
    "\n",
    "dictionary – name of the dictionary which should be converted to JSON object.\n",
    "file pointer – pointer of the file opened in write or append mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('person.json', 'w') as f:  # writing JSON object\n",
    "    json.dump(person, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "serialization using dumps() function\n",
    "json.dumps() that helps in converting a dictionary to a JSON object.\n",
    "\n",
    "It takes two parameters:\n",
    "\n",
    "dictionary – name of the dictionary which should be converted to JSON object.\n",
    "indent – defines the number of units for indentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serializing json  \n",
    "json_object = json.dumps(person, indent = 4) \n",
    "  \n",
    "# Writing to sample.json \n",
    "with open(\"sample.json\", \"w\") as outfile: \n",
    "    outfile.write(json_object) \n",
    "\n",
    "\n",
    "print(json_object)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading JSON to a File\n",
    "This process is usually called Deserialization - it is the reverse of serialization. It converts the special format returned by the serialization back into a usable object.\n",
    "\n",
    "Using json.load()\n",
    "The JSON package has json.load() function that loads the json content from a json file into a dictionary.\n",
    "\n",
    "It takes one parameter:\n",
    "\n",
    "File pointer: A file pointer that points to a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "  \n",
    "# Opening JSON file \n",
    "with open('sample.json', 'r') as openfile: \n",
    "  \n",
    "    # Reading from json file \n",
    "    json_object = json.load(openfile) \n",
    "  \n",
    "print(json_object) \n",
    "print(type(json_object))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XLSX file format\n",
    "\n",
    "\n",
    "XLSX is a Microsoft Excel Open XML file format. It is another type of Spreadsheet file format.\n",
    "\n",
    "In XLSX data is organized under the cells and columns in a sheet."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data from XLSX file\n",
    "\n",
    "Let’s load the data from XLSX file and define the sheet name. For loading the data you can use the Pandas library in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not needed unless you're running locally\n",
    "# import urllib.request\n",
    "# urllib.request.urlretrieve(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork/labs/Module%205/data/file_example_XLSX_10.xlsx\", \"sample.xlsx\")\n",
    "\n",
    "filename = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork/labs/Module%205/data/file_example_XLSX_10.xlsx\"\n",
    "\n",
    "async def download(url, filename):\n",
    "    response = await pyfetch(url)\n",
    "    if response.status == 200:\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(await response.bytes())\n",
    "\n",
    "await download(filename, \"file_example_XLSX_10.xlsx\")\n",
    "\n",
    "df = pd.read_excel(\"file_example_XLSX_10.xlsx\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XML file format\n",
    "XML is also known as Extensible Markup Language. As the name suggests, it is a markup language. It has certain rules for encoding data. XML file format is a human-readable and machine-readable file format.\n",
    "\n",
    "Pandas does not include any methods to read and write XML files. Here, we will take a look at how we can use other modules to read data from an XML file, and load it into a Pandas DataFrame.\n",
    "\n",
    "Writing with xml.etree.ElementTree\n",
    "The xml.etree.ElementTree module comes built-in with Python. It provides functionality for parsing and creating XML documents. ElementTree represents the XML document as a tree. We can move across the document using nodes which are elements and sub-elements of the XML file.\n",
    "\n",
    "For more information please read the xml.etree.ElementTree documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# create the file structure\n",
    "employee = ET.Element('employee')\n",
    "details = ET.SubElement(employee, 'details')\n",
    "first = ET.SubElement(details, 'firstname')\n",
    "second = ET.SubElement(details, 'lastname')\n",
    "third = ET.SubElement(details, 'age')\n",
    "first.text = 'Shiv'\n",
    "second.text = 'Mishra'\n",
    "third.text = '23'\n",
    "\n",
    "# create a new XML file with the results\n",
    "mydata1 = ET.ElementTree(employee)\n",
    "# myfile = open(\"items2.xml\", \"wb\")\n",
    "# myfile.write(mydata)\n",
    "with open(\"new_sample.xml\", \"wb\") as files:\n",
    "    mydata1.write(files)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading with xml.etree.ElementTree\n",
    "Let's have a look at a one way to read XML data and put it in a Pandas DataFrame. You can see the XML file in the Notepad of your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not needed unless running locally\n",
    "# !wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork/labs/Module%205/data/Sample-employee-XML-file.xml\n",
    "\n",
    "import xml.etree.ElementTree as etree\n",
    "\n",
    "filename = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork/labs/Module%205/data/Sample-employee-XML-file.xml\"\n",
    "\n",
    "async def download(url, filename):\n",
    "    response = await pyfetch(url)\n",
    "    if response.status == 200:\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(await response.bytes())\n",
    "\n",
    "await download(filename, \"Sample-employee-XML-file.xml\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You would need to firstly parse an XML file and create a list of columns for data frame, then extract useful information from the XML file and add to a pandas data frame.\n",
    "\n",
    "Here is a sample code that you can use.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = etree.parse(\"Sample-employee-XML-file.xml\")\n",
    "\n",
    "root = tree.getroot()\n",
    "columns = [\"firstname\", \"lastname\", \"title\", \"division\", \"building\",\"room\"]\n",
    "\n",
    "datatframe = pd.DataFrame(columns = columns)\n",
    "\n",
    "for node in root: \n",
    "\n",
    "    firstname = node.find(\"firstname\").text\n",
    "\n",
    "    lastname = node.find(\"lastname\").text \n",
    "\n",
    "    title = node.find(\"title\").text \n",
    "    \n",
    "    division = node.find(\"division\").text \n",
    "    \n",
    "    building = node.find(\"building\").text\n",
    "    \n",
    "    room = node.find(\"room\").text\n",
    "    \n",
    "    datatframe = datatframe.append(pd.Series([firstname, lastname, title, division, building, room], index = columns), ignore_index = True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
